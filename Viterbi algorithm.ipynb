{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Viterbi Algorithm\n",
    "Write a computer program for computing the messages m1:1, m1:2, m1:3, m1:4, m1:5,\n",
    "and the most likely sequence of states in Figure 15.5. See slides #16-24 in “Chapter15 Probabilistic\n",
    "Reasoning over Time.pdf” for detailed calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "I implemented a viterbi algorithm to find the messages m1:1, m1:2, m1:3, m1:4, m1:5 and likely sequence of hidden states (rain or no rain) given Observations sequence for umbrella {True, True, True, False, True}.\n",
    "\n",
    "To avoid many lines of codes which can be hard to understand for the main implementation, I created a viterbi_utils python file that contains basic calculations such as vector addition, pairwise matrix multiplication, etc. So, to reproduce the results, Make sure to import all functions from viterbi_utils or implement them yourself. The implementation will work perfectly with Python3 but it can be modified to fit other versions. \n",
    "\n",
    "Below are implementation steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Creating an Hidden Markov Model\n",
    "First I created an HMM class which takes takes transion probability and sensor model matrices, and priors (if neccessary) as its inputs. These matrices will be input to our viterbi computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from viterbi_utils import *\n",
    "# from probability import backward,forward\n",
    "class HMM_Model:\n",
    "\n",
    "    def __init__(self, trans_matrix, sensor_matrix, prior=None):\n",
    "        self.trans_matrix= trans_matrix\n",
    "        self.sensor_matrix = sensor_matrix\n",
    "        \n",
    "        # Initialize the prior or otherwise there will be uniformly distributed\n",
    "        self.prior = prior or [0.5, 0.5]\n",
    "\n",
    "    def sensor_dist(self, ev):\n",
    "        if ev is True:\n",
    "            return self.sensor_matrix[0]\n",
    "        else:\n",
    "            return self.sensor_matrix[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Computing Forward back ward messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_message(HMM, fv, ev):\n",
    "    prediction = vector_add(scalar_vector_product(fv[0], HMM. trans_matrix[0]),\n",
    "                            scalar_vector_product(fv[1], HMM. trans_matrix[1]))\n",
    "    sensor_dist = HMM.sensor_dist(ev)\n",
    "\n",
    "    return normalize(element_wise_product(sensor_dist, prediction))\n",
    "\n",
    "\n",
    "def Backward_message(HMM, b, ev):\n",
    "    sensor_dist = HMM.sensor_dist(ev)\n",
    "    prediction = element_wise_product(sensor_dist, b)\n",
    "\n",
    "    return normalize(vector_add(scalar_vector_product(prediction[0], HMM. trans_matrix[0]),\n",
    "                                scalar_vector_product(prediction[1], HMM. trans_matrix[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Viterbi algorithm\n",
    "Below is the actual implementation of viterbi algorithm following $Equation 15.11$ from the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_compute(HMM, ev):\n",
    "    t = len(ev)\n",
    "    ev = ev.copy()\n",
    "    ev.insert(0, None)\n",
    "\n",
    "    m = [[0.0, 0.0] for _ in range(len(ev) - 1)]\n",
    "\n",
    "    # Initialiaze recursion with the first message m1\n",
    "    m[0] = Forward_message(HMM, HMM.prior, ev[1])\n",
    "    \n",
    "    # We back track the state status  at each t-1.\n",
    "    m_back_tracking= []\n",
    "\n",
    "    for i in range(1, t):\n",
    "        ## Message at time t\n",
    "        m[i] = element_wise_product(HMM.sensor_dist(ev[i + 1]),\n",
    "                                    [max(element_wise_product(HMM.trans_matrix[0], m[i - 1])),\n",
    "                                     max(element_wise_product(HMM.trans_matrix[1], m[i - 1]))])\n",
    "        ## Keep track of message at t-1\n",
    "        m_back_tracking.append([np.argmax(element_wise_product(HMM.trans_matrix[0], m[i - 1])),\n",
    "                                   np.argmax(element_wise_product(HMM.trans_matrix[1], m[i - 1]))])\n",
    "\n",
    "    # Initialize Message probability \n",
    "    message_probs= [0.0] * (len(ev) - 1)\n",
    "    \n",
    "    # Initialize most likely path sequence\n",
    "    message_path = [True] * (len(ev) - 1)\n",
    "    \n",
    "\n",
    "    # We start from the final state with largest probability and move backward while keeping track for\n",
    "    # each time t the processor state xt-1 that maxmize probability of xt\n",
    "\n",
    "    i_max = np.argmax(m[-1])\n",
    "\n",
    "    for i in range(t - 1, -1, -1):\n",
    "        message_probs[i] = m[i][i_max]\n",
    "        message_path[i] = True if i_max == 0 else False\n",
    "        if i > 0:\n",
    "            i_max = m_back_tracking[i - 1][i_max]\n",
    "\n",
    "    return message_path, message_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_transition_mat= [[0.7, 0.3], [0.3, 0.7]]\n",
    "sensor_mat= [[0.9, 0.2], [0.1, 0.8]]\n",
    "hmm = HMM_Model(state_transition_mat, sensor_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([True, True, False, True, True],\n",
       " [0.8181818181818181,\n",
       "  0.5154545454545454,\n",
       "  0.12370909090909088,\n",
       "  0.03340145454545454,\n",
       "  0.02104291636363636])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ummbrella_evidence= [True, True, False, True, True]\n",
    "\n",
    "# rounder(viterbi(umbrellaHMM, umbrella_evidence))\n",
    "viterbi_compute(hmm, ummbrella_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "observations=[1,1,0,1,1]\n",
    "umbrella_transition =np.array( [[0.7, 0.3], [0.3, 0.7]])\n",
    "umbrella_sensor = np.array([[0.9, 0.2], [0.1, 0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def viterbi(y, A, B, Pi=None):\n",
    "    \"\"\"\n",
    "    Return the MAP estimate of state trajectory of Hidden Markov Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array (T,)\n",
    "        Observation state sequence. int dtype.\n",
    "    A : array (K, K)\n",
    "        State transition matrix. See HiddenMarkovModel.state_transition  for\n",
    "        details.\n",
    "    B : array (K, M)\n",
    "        Emission matrix. See HiddenMarkovModel.emission for details.\n",
    "    Pi: optional, (K,)\n",
    "        Initial state probabilities: Pi[i] is the probability x[0] == i. If\n",
    "        None, uniform initial distribution is assumed (Pi[:] == 1/K).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : array (T,)\n",
    "        Maximum a posteriori probability estimate of hidden state trajectory,\n",
    "        conditioned on observation sequence y under the model parameters A, B,\n",
    "        Pi.\n",
    "    T1: array (K, T)\n",
    "        the probability of the most likely path so far\n",
    "    T2: array (K, T)\n",
    "        the x_j-1 of the most likely path so far\n",
    "    \"\"\"\n",
    "    # Cardinality of the state space\n",
    "    K = A.shape[0]\n",
    "    # Initialize the priors with default (uniform dist) if not given by caller\n",
    "    Pi = Pi if Pi is not None else np.full(K, 1 / K)\n",
    "    T = len(y)\n",
    "    T1 = np.empty((K, T), 'd')\n",
    "    T2 = np.empty((K, T), 'B')\n",
    "\n",
    "    # Initilaize the tracking tables from first observation\n",
    "    T1[:, 0] = Pi * B[:, y[0]]\n",
    "    T2[:, 0] = 0\n",
    "\n",
    "    # Iterate throught the observations updating the tracking tables\n",
    "    for i in range(1, T):\n",
    "        T1[:, i] = np.max(T1[:, i - 1] * A.T * B[np.newaxis, :, y[i]].T, 1)\n",
    "        T2[:, i] = np.argmax(T1[:, i - 1] * A.T, 1)\n",
    "\n",
    "    # Build the output, optimal model trajectory\n",
    "    x = np.empty(T, 'B')\n",
    "    x[-1] = np.argmax(T1[:, T - 1])\n",
    "    for i in reversed(range(1, T)):\n",
    "        x[i - 1] = T2[x[i], i]\n",
    "\n",
    "    return x, T1, T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,t1,t2=viterbi(observations,umbrella_transition,umbrella_sensor)\n",
    "print(x)\n",
    "print(t1)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def viterbi_path(prior, transmat, obslik, scaled=True, ret_loglik=False):\n",
    "    '''Finds the most-probable (Viterbi) path through the HMM state trellis\n",
    "    Notation:\n",
    "        Z[t] := Observation at time t\n",
    "        Q[t] := Hidden state at time t\n",
    "    Inputs:\n",
    "        prior: np.array(num_hid)\n",
    "            prior[i] := Pr(Q[0] == i)\n",
    "        transmat: np.ndarray((num_hid,num_hid))\n",
    "            transmat[i,j] := Pr(Q[t+1] == j | Q[t] == i)\n",
    "        obslik: np.ndarray((num_hid,num_obs))\n",
    "            obslik[i,t] := Pr(Z[t] | Q[t] == i)\n",
    "        scaled: bool\n",
    "            whether or not to normalize the probability trellis along the way\n",
    "            doing so prevents underflow by repeated multiplications of probabilities\n",
    "        ret_loglik: bool\n",
    "            whether or not to return the log-likelihood of the best path\n",
    "    Outputs:\n",
    "        path: np.array(num_obs)\n",
    "            path[t] := Q[t]\n",
    "    '''\n",
    "    num_hid = obslik.shape[0] # number of hidden states\n",
    "    num_obs = obslik.shape[1] # number of observations (not observation *states*)\n",
    "\n",
    "    # trellis_prob[i,t] := Pr((best sequence of length t-1 goes to state i), Z[1:(t+1)])\n",
    "    trellis_prob = np.zeros((num_hid,num_obs))\n",
    "    # trellis_state[i,t] := best predecessor state given that we ended up in state i at t\n",
    "    trellis_state = np.zeros((num_hid,num_obs), dtype=int) # int because its elements will be used as indicies\n",
    "    path = np.zeros(num_obs, dtype=int) # int because its elements will be used as indicies\n",
    "\n",
    "    trellis_prob[:,0] = prior * obslik[:,0] # element-wise mult\n",
    "    if scaled:\n",
    "        scale = np.ones(num_obs) # only instantiated if necessary to save memory\n",
    "        scale[0] = 1.0 / np.sum(trellis_prob[:,0])\n",
    "        trellis_prob[:,0] *= scale[0]\n",
    "\n",
    "    trellis_state[:,0] = 0 # arbitrary value since t == 0 has no predecessor\n",
    "    for t in range(1, num_obs):\n",
    "        for j in range(num_hid):\n",
    "            trans_probs = trellis_prob[:,t-1] * transmat[:,j] # element-wise mult\n",
    "            trellis_state[j,t] = trans_probs.argmax()\n",
    "            trellis_prob[j,t] = trans_probs[trellis_state[j,t]] # max of trans_probs\n",
    "            trellis_prob[j,t] *= obslik[j,t]\n",
    "        if scaled:\n",
    "            scale[t] = 1.0 / np.sum(trellis_prob[:,t])\n",
    "            trellis_prob[:,t] *= scale[t]\n",
    "\n",
    "    path[-1] = trellis_prob[:,-1].argmax()\n",
    "    for t in range(num_obs-2, -1, -1):\n",
    "        path[t] = trellis_state[(path[t+1]), t+1]\n",
    "\n",
    "    if not ret_loglik:\n",
    "        return path\n",
    "    else:\n",
    "        if scaled:\n",
    "            loglik = -np.sum(np.log(scale))\n",
    "        else:\n",
    "            p = trellis_prob[path[-1],-1]\n",
    "            loglik = np.log(p)\n",
    "        return path, loglik\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Assume there are 3 observation states, 2 hidden states, and 5 observations\n",
    "    priors = np.array([0.5, 0.5])\n",
    "    transmat = np.array([\n",
    "        [0.7, 0.3],\n",
    "        [0.7, 0.7]])\n",
    "    emmat = np.array([\n",
    "        [0.9, 0.2],\n",
    "        [0.1, 0.8]])\n",
    "    observations = np.array([1,1,1,0,1], dtype=int)\n",
    "    obslik = np.array([emmat[:,z] for z in observations]).T\n",
    "    print (viterbi_path(priors, transmat, obslik))                             \n",
    "    print (viterbi_path(priors, transmat, obslik, scaled=False))                 \n",
    "    print (viterbi_path(priors, transmat, obslik, ret_loglik=True))               \n",
    "    print (viterbi_path(priors, transmat, obslik, scaled=False, ret_loglik=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=> [0 1 1 1 0]\n",
    "#=> [0 1 1 1 0]\n",
    "#=> (array([0, 1, 1, 1, 0]), -7.776472586614755)\n",
    "#=> (array([0, 1, 1, 1, 0]), -8.0120386579275227)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
